---
title: "Covid-19"
author: "Thibault Herpe"
date: "19/05/2020"
output: html_document
---

Our goal is to retrieve data from different databases and analyse it to find out if correlation can be found between the political regime and the number of deaths from the SARS-CoV-2 commonly named covid-19.

# Collecting Data
## Sherbrook University
### Democracy Index

First we start by retrieving democracy index from Sherbrook University (EIU.DEMO.GLOBAL, 2017, 163 Countries)
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=TRUE}

#Retrieving DEMOCRACY INDEX from Sherbrook University (EIU.DEMO.GLOBAL, 2017, 163 Countries)

Democracy.Index =c( 2.55, 7.24, 5.98, 3.56, 8.61, 3.62, 1.93, 6.96, 4.11, 9.09, 8.42, 2.65, 2.71, 5.43, 3.13, 7.78, 5.61, 5.08, 5.49, 4.87, 7.81, 6.86, 7.03, 4.75, 2.33, 3.63, 3.61, 9.15, 7.88, 1.52, 7.84, 3.1, 7.59, 6.67, 3.71, 3.25, 1.61, 1.08, 8, 7.88, 3.93, 6.63, 3.31, 9.22, 2.76, 6.66, 3.36, 2.69, 6.02, 2.37, 8.08, 7.79, 3.03, 7.98, 3.42, 9.03, 7.8, 3.61, 4.06, 5.93, 6.69, 7.29, 5.86, 3.14, 1.81, 1.98, 6.46, 4.03, 5.72, 6.64, 7.23, 6.39, 4.09, 2.45, 9.15, 9.58, 7.79, 7.98, 7.29, 7.88, 3.87, 3.06, 5.11, 5.11, 3.85, 2.37, 6.64, 7.25, 4.72, 5.23, 2.32, 7.41, 8.81, 5.57, 5.11, 6.54, 5.49, 5.64, 4.87, 8.22, 3.82, 6.41, 5.94, 6.5, 5.69, 4.02, 3.83, 6.31, 5.18, 4.66, 3.76, 4.44, 9.87, 9.26, 3.04, 5.09, 1.95, 4.26, 7.08, 6.03, 6.31, 8.89, 6.49, 6.71, 6.67, 7.84, 3.19, 6.44, 8.53, 3.17, 3.19, 6.43, 6.15, 6.41, 4.66, 6.32, 7.16, 7.5, 2.15, 6.48, 9.39, 9.03, 6.76, 1.43, 1.93, 7.73, 5.47, 1.5, 7.62, 4.63, 7.19, 3.05, 7.04, 6.32, 1.72, 4.88, 5.69, 8.12, 3.87, 3.08, 2.07, 5.68, 3.16)

#Retrieving ISO COUNTRY CODE from Sherbrook University

ISO = c( "AFG", "ZAF", "ALB", "DZA", "DEU", "AGO", "SAU", "ARG", "ARM", "AUS", "AUT", "AZE", "BHR", "BGD", "BLR", "BEL", "BEN", "BTN", "BOL", "BIH", "BWA", "BRA", "BGR", "BFA", "BDI", "KHM", "CMR", "CAN", "CPV", "CAF", "CHL", "CHN", "CYP", "COL", "COM", "COG", "COD", "PRK", "KOR", "CRI", "CIV", "HRV", "CUB", "DNK", "DJI", "DOM", "EGY", "ARE", "ECU", "ERI", "ESP", "EST", "SWZ", "USA", "ETH", "FIN", "FRA", "GAB", "GMB", "GEO", "GHA", "GRC", "GTM", "GIN", "GNQ", "GNB", "GUY", "HTI", "HND", "HUN", "IND", "IDN", "IRQ", "IRN", "IRL", "ISL", "ISR", "ITA", "JAM", "JPN", "JOR", "KAZ", "KEN", "KGZ", "KWT", "LAO", "LSO", "LVA", "LBN", "LBR", "LBY", "LTU", "LUX", "MKD", "MDG", "MYS", "MWI", "MLI", "MAR", "MUS", "MRT", "MEX", "MDA", "MNG", "MON", "MOZ", "MMR", "NAM", "NPL", "NIC", "NER", "NGA", "NOR", "NZL", "OMN", "UGA", "UZB", "PAK", "PAN", "PNG", "PRY", "NLD", "PER", "PHL", "POL", "PRT", "QAT", "ROM", "GBR", "RUS", "RWA", "SLV", "SEN", "YUG", "SLE", "SGP", "SVK", "SVN", "SDN", "LKA", "SWE", "CHE", "SUR", "SYR", "TJK", "TWN", "TZA", "TCD", "CZE", "THA", "TMP", "TGO", "TTO", "TUN", "TKM", "TUR", "UKR", "URY", "VEN", "VNM", "YEM", "ZMB", "ZWE")

```


```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}

#Creation of a DATAFRAME called DEMOCRACY

democracy = data.frame(ISO,Democracy.Index)

#Ordering DEMOCRACY DATAFRAME by alphabetical order on ISO COUNTRY CODE

democracy <- democracy[order(ISO),]

```


```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}

#Writing of the DEMOCRACY INDEX EXCEL FILE

library(writexl)

write_xlsx(x = democracy, path = "Datasets/dataset_democracy_index.xlsx", col_names = TRUE)

```


### Press Liberty Index


We continue by retrieving the press liberty index from Sherbrook University (PF.LIB.PRESS.RSF.IN, 2017, 166 Countries)

```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=TRUE}

#Retrieving PRESS LIBERTY INDEX from Sherbrook University (PF.LIB.PRESS.RSF.IN, 2017, 166 Countries)

PRESS.LIBERTY.INDEX =c( 39.46, 20.12, 29.92, 42.83, 14.97, 40.42, 66.02, 25.07, 30.38, 16.02, 13.47, 56.4, 58.88, 48.36, 52.43, 12.75, 30.32, 30.73, 33.88, 27.83, 24.93, 33.58, 35.01, 23.85, 55.78, 42.07, 41.59, 16.53, 18.02, 36.12, 20.53, 77.66, 19.79, 41.47, 24.33, 36.73, 52.67, 84.98, 27.61, 11.93, 30.42, 29.59, 71.75, 10.36, 70.54, 26.76, 55.78, 39.39, 33.64, 84.24, 18.69, 13.55, 51.27, 23.88, 50.34, 8.92, 22.24, 34.83, 46.7, 27.76, 17.95, 30.89, 39.33, 33.15, 66.47, 30.09, 26.8, 26.36, 43.75, 29.01, 42.94, 39.93, 54.03, 65.12, 14.08, 13.03, 31.01, 26.26, 12.73, 29.44, 43.24, 54.01, 31.2, 30.92, 30.45, 33.61, 66.41, 28.78, 18.62, 33.01, 31.12, 56.81, 21.37, 14.72, 35.74, 26.71, 46.89, 28.97, 38.27, 42.42, 26.67, 26.49, 48.97, 30.41, 28.95, 33.65, 31.05, 41.82, 17.08, 33.02, 31.01, 27.21, 39.69, 7.6, 13.98, 40.46, 35.94, 66.11, 43.55, 32.12, 25.07, 35.64, 11.28, 30.98, 41.08, 26.47, 15.77, 39.83, 24.46, 22.26, 49.45, 54.11, 27.24, 26.72, 28.05, 30.73, 51.1, 15.51, 21.7, 65.95, 73.56, 48.16, 44.34, 8.27, 12.13, 16.07, 81.49, 50.27, 24.37, 30.65, 39.66, 16.91, 44.69, 32.82, 30.75, 20.62, 32.22, 84.19, 52.98, 33.19, 17.43, 42.94, 73.96, 65.8, 36.48, 41.44)

#Retrieving ISO COUNTRY CODE from Sherbrook University

ISO = c(  "AFG", "ZAF", "ALB", "DZA", "DEU", "AGO", "SAU", "ARG", "ARM", "AUS", "AUT", "AZE", "BHR", "BGD", "BLR", "BEL", "BEN", "BTN", "BOL", "BIH", "BWA", "BRA", "BGR", "BFA", "BDI", "KHM", "CMR", "CAN", "CPV", "CAF", "CHL", "CHN", "CYP", "COL", "COM", "COG", "COD", "PRK", "KOR", "CRI", "CIV", "HRV", "CUB", "DNK", "DJI", "DOM", "EGY", "ARE", "ECU", "ERI", "ESP", "EST", "SWZ", "USA", "ETH", "FIN", "FRA", "GAB", "GMB", "GEO", "GHA", "GRC", "GTM", "GIN", "GNQ", "GNB", "GUY", "HTI", "HND", "HUN", "IND", "IDN", "IRQ", "IRN", "IRL", "ISL", "ISR", "ITA", "JAM", "JPN", "JOR", "KAZ", "KEN", "KGZ", "KSV", "KWT", "LAO", "LSO", "LVA", "LBN", "LBR", "LBY", "LTU", "LUX", "MKD", "MDG", "MYS", "MWI", "MLI", "MAR", "MUS", "MRT", "MEX", "MDA", "MNG", "MON", "MOZ", "MMR", "NAM", "NPL", "NIC", "NER", "NGA", "NOR", "NZL", "OMN", "UGA", "UZB", "PAK", "PAN", "PNG", "PRY", "NLD", "PER", "PHL", "POL", "PRT", "QAT", "ROM", "GBR", "RUS", "RWA", "SLV", "SEN", "YUG", "SLE", "SGP", "SVK", "SVN", "SOM", "SDN", "SSD", "LKA", "SWE", "CHE", "SUR", "SYR", "TJK", "TWN", "TZA", "TCD", "CZE", "THA", "TMP", "TGO", "TTO", "TUN", "TKM", "TUR", "UKR", "URY", "VEN", "VNM", "YEM", "ZMB", "ZWE")

```


```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}

#Creation of a DATAFRAME called PRESS

press = data.frame(ISO,PRESS.LIBERTY.INDEX)

#Ordering PRESS DATAFRAME by alphabetical order on ISO COUNTRY CODE

press <- press[order(ISO),]

#TRANSFORMING the REPRESSION PRESS INDEX into a LIBERTY PRESS INDEX
press$Press.Liberty.Index <- 100 - press$PRESS.LIBERTY.INDEX

#DELETING the old REPRESSION COLUMN
press$PRESS.LIBERTY.INDEX <- NULL

```


```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}

#Writing of the PRESS LIBERTY INDEX EXCEL FILE

library(writexl)

write_xlsx(x = press, path = "Datasets/dataset_press_liberty_index.xlsx", col_names = TRUE)

```


## European Union Open Data Portal
### Covid 19 Cases

Then we retrieve covid-19 cases from the European Union Open Data Portal (Covid 19 cases, 28-04-2020, --- Countries)
```{r setup, include=FALSE}
library(readr)

# Downloading data from the Data Europa Portal and saving xlsx file into covid19_cases variable
covid19_cases <- read_csv("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv")


#Deleting unwanted columns
covid19_cases[,1] <- NULL
covid19_cases[,7] <- NULL
covid19_cases[,9] <- NULL

#Renaming columns
names(covid19_cases)[1] <- "Day"
names(covid19_cases)[2] <- "Month"
names(covid19_cases)[3] <- "Year"
names(covid19_cases)[4] <- "Cases"
names(covid19_cases)[5] <- "Deaths"
names(covid19_cases)[6] <- "Country"
names(covid19_cases)[7] <- "ISO"
names(covid19_cases)[8] <- "Population"

head(covid19_cases)

```


```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
#Writing of the DATASET EXCEL FILE

library(writexl)

write_xlsx(x = covid19_cases, path = "Datasets/dataset_covid19_cases_index.xlsx", col_names = TRUE)

```

## World Bank
### Per Capita Income Index

We continue by retrieving the Per Capita Income from the World Bank (NY.GNP.PCAP.CD, 2018, 229 Countries)
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
library(WDI)
library(plyr)

#RETRIEVING of the RNB PER INHABITANT for ALL COUNTRIES
RNB_hab_year <- WDI(indicator = "NY.GNP.PCAP.CD", 
                   country = "all", 
                   start = 2018, 
                   end = NULL)


#Handling MISSING VALUES
RNB_hab_year <- na.omit(RNB_hab_year)

#RENAMING of COLUMNS
names(RNB_hab_year)[1] <- "ISO2"
names(RNB_hab_year)[2] <- "Country"
names(RNB_hab_year)[3] <- "RNB.Inhab.Year"


#DELETING UNWANTED COLMUNS
RNB_hab_year$year <- NULL
RNB_hab_year[2] <- NULL

#na.omit(RNB_hab_year)

```

We load voice accountability index, corruption index, rule of law index and govnerment effectiveness index from the World Governance Indicators data base of the World Bank (2018)
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
library(readxl)
library(dplyr)

#LOADING WGI dataset VOICE ACCOUNTABILITY
dataset_WGI1 <- read_excel("Datasets/World Governance Indicator/dataset_WGI_2018_Voice_Accountability.xlsx")


#DELETING specific ROWS where values == #N/A
#JAI PAS TROUVE DE FONCTION POUR FAIRE CA SUPPRIMER UN HASHTAG NA ... VOUS EN CONNAISSEZ ?
dataset_WGI1 <- subset(dataset_WGI1, Estimate != "#N/A")


#DELETING UNWANTED COLUMNS
dataset_WGI1 <- dataset_WGI1[1:3]

#RENAMING COLUMNS 
names(dataset_WGI1)[1] <- "Country"
names(dataset_WGI1)[2] <- "ISO"
names(dataset_WGI1)[3] <- "Voice Accountability"


#################################################################
#LOADING WGI dataset CORRUPTION
dataset_WGI2 <- read_excel("Datasets/World Governance Indicator/dataset_WGI_2018_Corruption.xlsx")


#DELETING specific ROWS where values == #N/A
dataset_WGI2 <- subset(dataset_WGI2, Estimate != "#N/A")

#DELETING UNWANTED COLUMNS
dataset_WGI2 <- dataset_WGI2[1:3]

#RENAMING COLUMNS 
names(dataset_WGI2)[1] <- "Country"
names(dataset_WGI2)[2] <- "ISO"
names(dataset_WGI2)[3] <- "Corruption"

#################################################################
#LOADING WGI dataset RULE OF LAW
dataset_WGI3 <- read_excel("Datasets/World Governance Indicator/dataset_WGI_2018_Rule_of_Law.xlsx")


#DELETING specific ROWS where values == #N/A
dataset_WGI3 <- subset(dataset_WGI3, Estimate != "#N/A")

#DELETING UNWANTED COLUMNS
dataset_WGI3 <- dataset_WGI3[1:3]

#RENAMING COLUMNS 
names(dataset_WGI3)[1] <- "Country"
names(dataset_WGI3)[2] <- "ISO"
names(dataset_WGI3)[3] <- "Rule of Law"

#################################################################
#LOADING WGI dataset GOVERNMENT EFFECTIVENESS
dataset_WGI4 <- read_excel("Datasets/World Governance Indicator/dataset_WGI_2018_Government_Effectiveness.xlsx")


#DELETING specific ROWS where values == #N/A
dataset_WGI4 <- subset(dataset_WGI4, Estimate != "#N/A")

#DELETING UNWANTED COLUMNS
dataset_WGI4 <- dataset_WGI4[1:3]

#RENAMING COLUMNS 
names(dataset_WGI4)[1] <- "Country"
names(dataset_WGI4)[2] <- "ISO"
names(dataset_WGI4)[3] <- "Government Effectiveness"

```


## World Health Organisation (WHO)
### Universal Health Coverage Index

Finally we load the Universal Health Coverage (UHC) - Service Capacity and Acess index from the World Health Organization (2018)
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
library(readxl)
library(dplyr)

#IMPORT and SAVING of ISO COUNTRY CODE index
service_capacity_access <- read_excel("Datasets/UHC-service_capacity_access.xlsx")

```


# Data Wrangling

Merging the press liberty index with the democracy index
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}

#MERGING the PRESS LIBERTY INDEX with the DEMOCRACY INDEX (different rows in ISO CODE)

dataset_intermediaire_clustering = merge(press, democracy, by="ISO")

```

Creation of a translation index for ISO country code and country name
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
library(readxl)
library(dplyr)

#IMPORT and SAVING of ISO COUNTRY CODE index
ISO_COUNTRY_REDUCED <- read_excel("Datasets/ISO_COUNTRY_TRANSLATION_V2.xlsx")


ISO_COUNTRY_REDUCED <- filter(ISO_COUNTRY_REDUCED, ISO_COUNTRY_REDUCED$ISO != "N/A")

```

Saving of the iso_country_reduced index in a dataset excel file
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
#Writing of the DATASET EXCEL FILE
library(writexl)

write_xlsx(x = ISO_COUNTRY_REDUCED, path = "Datasets/iso_country_reduced.xlsx", col_names = TRUE)

```


Filtering and summarizing of Death cases and Confirmed cases within the dataset final excel file. 
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
library(dplyr)


#FILTERING DEATHS CASES in the covid19_cases sum up file
sum_deaths_country <- covid19_cases %>% 
  group_by(ISO) %>%  
  summarize(Deaths.Cases = sum(Deaths, na.rm=TRUE))


#FILTERING CONFIRMED CASES in the covid19_cases sum up file
sum_confirmed_country <- covid19_cases %>% 
  group_by(ISO) %>%  
  summarize(Confirmed.Cases = sum(Cases, na.rm=TRUE))


#FILTERING POPULATION in the covid19_cases sum up file
 population_country <- covid19_cases %>% 
  group_by(ISO) %>%  
  summarize(Population = mean(Population, na.rm=TRUE))
 

```

Merging death cases sum, confirmed cases sum and country's population in the dataset final file 
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
library(dplyr)

#LOADINF of the ISO COUNTRY CODE into DATASET INTERMEDIAIRE COVID
dataset_intermediaire_covid <- ISO_COUNTRY_REDUCED

#MERGING DEATH CASES SUM and DATASET INTERMEDIAIRE COVID by ISO code
dataset_intermediaire_covid = merge(sum_deaths_country, dataset_intermediaire_covid, by = "ISO")

#MERGING CONFIRMED CASES SUM and DATASET INTERMEDIAIRE COVID by ISO code
dataset_intermediaire_covid = merge(sum_confirmed_country, dataset_intermediaire_covid, by = "ISO")

#MERGING POPULATION COUNTRY SUM and DATASET INTERMEDIAIRE COVID by ISO code
dataset_intermediaire_covid = merge(population_country, dataset_intermediaire_covid, by = "ISO")

```


```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}

#MOVING COLUMNS in order to have COUNTRY'S NAME as FIRST COLUMN
dataset_intermediaire_covid <- dataset_intermediaire_covid[, c(1, 5, 6, 2, 3, 4)]

```

Calculation of Deaths ratio and confirmed cases among the total population, deaths ratio among confirmed cases.
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}

#MOVING COLUMNS in order to have country's name as first column

dataset_intermediaire_covid$Death.Ratio.Population <- (dataset_intermediaire_covid$Deaths.Cases / dataset_intermediaire_covid$Population) * 1000000
dataset_intermediaire_covid$Confirmed.Ratio.Population <- (dataset_intermediaire_covid$Confirmed.Cases / dataset_intermediaire_covid$Population) * 1000000
dataset_intermediaire_covid$Death.Ratio.Confirmed <- (dataset_intermediaire_covid$Deaths.Cases / dataset_intermediaire_covid$Confirmed.Cases) * 100
```

Saving data in a dataset excel file
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}

dataset_final_covid <- dataset_intermediaire_covid

#Writing of the DATASET EXCEL FILE
library(writexl)

write_xlsx(x = dataset_final_covid, path = "Datasets/dataset_final_covid.xlsx", col_names = TRUE)

```

Merging the intermediary clustering dataset with the per capita income by year
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
library(dplyr)


#INNER_JOIN the RNB PER INHABITANT with the DATASET FINAL (different rows in ISO CODE)
dataset_intermediaire_clustering = inner_join(dataset_intermediaire_covid, RNB_hab_year, by = "ISO2")
dataset_intermediaire_clustering = inner_join(dataset_intermediaire_clustering, press, by = "ISO")
dataset_intermediaire_clustering = inner_join(dataset_intermediaire_clustering, democracy, by = "ISO")

#DELETING UNWANTED COLUMNS
dataset_intermediaire_clustering[3:9] <- NULL
#dataset_Eco[5:7] <- NULL


```

Merging of voice accountability index, corruption index, rule of law index and govnerment effectiveness index together
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}

#MERGING VOICE ACCOUNTABILITY and CORRUPTION by ISO code
dataset_WGI2$Country  <- NULL
dataset_intermediaire_WGI = merge(dataset_WGI1, dataset_WGI2, by = "ISO")


#MERGING VOICE ACCOUNTABILITY, CORRUPTION and RULE of LAW by ISO code
dataset_WGI3$Country  <- NULL
dataset_intermediaire_WGI = merge(dataset_intermediaire_WGI, dataset_WGI3, by = "ISO")

#MERGING VOICE ACCOUNTABILITY, CORRUPTION, RULE of LAW and GOVERNMENT EFFECTIVENESS by ISO code
dataset_WGI4$Country  <- NULL
dataset_intermediaire_WGI = merge(dataset_intermediaire_WGI, dataset_WGI4, by = "ISO")

#MERGING VOICE ACCOUNTABILITY, CORRUPTION, RULE of LAW and GOVERNMENT EFFECTIVENESS by ISO code
dataset_intermediaire_WGI$Country  <- NULL
dataset_intermediaire_clustering = merge(dataset_intermediaire_clustering, dataset_intermediaire_WGI, by = "ISO")

```


Combining of ISO country code translation file and Universal Health Coverage (UHC) - Service Capacity and Acess index
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
library(dplyr)

#TESTING differences existance
dataset_antijoin = anti_join(service_capacity_access, ISO_COUNTRY_REDUCED, by = "Country")

#JOINING SERVICE CAPACITY and ACCESS with ISO COUNTRY file
service_capacity_access_index = full_join(service_capacity_access, ISO_COUNTRY_REDUCED, by = "Country")

service_capacity_access_index <- na.omit(service_capacity_access_index)

names(service_capacity_access_index)[2] <- "Service Capacity and Access"

#SAVING and WRITING of the DATASET EXCEL FILE
library(writexl)

write_xlsx(x = service_capacity_access_index, path = "Datasets/service_capacity_access_index.xlsx", col_names = TRUE)

```

Merging dataset final and service capacity and access index.
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}

#MERGING DATASET INTERMEDIAIRE CLUSTERING and SERVICE CAPACITY ACCESS INDEX by ISO code
service_capacity_access_index$Country  <- NULL
dataset_final_clustering = merge(dataset_intermediaire_clustering, service_capacity_access_index, by = "ISO")
dataset_final_clustering$ISO2 <- NULL

```

Saving dataset World Governance Indicator plus Access and Capacity to the Health Care system in a excel file
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}

#SAVING DATASET FINAL in a EXCEL FILE
write_xlsx(x = dataset_final_clustering, path = "Datasets/dataset_final_WGI_capacity_access.xlsx", col_names = TRUE)

```


Saving dataset final in a excel file
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}

#SAVING DATASET FINAL in a EXCEL FILE
write_xlsx(x = dataset_final_clustering, path = "Datasets/dataset_intermediaire_clustering.xlsx", col_names = TRUE)

```


# Data Analysis

Now that we've got our final dataset regrouping, for 196 countries, informations about the covid-19 such as : Comfired cases number, Death cases number and ratio like dead person among confirmed person, confirmed cases among total population, Death cases among total population but also the total population of the country and their ISO code and names. We decided to run a correlation test to find patterns that could be interesting and to complete this test by a p-value test. We want to confirm if correlation found are real one, in other words that those correlations are significant or not. To run this final test, the p-value chosen was 0.05.

## Correlation tests and p-value analysis
```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}
library(corrplot)

#LOADIND and SAVING of DATASET FINAL
dataset_intermediaire_covid_correl <- select(dataset_final_covid, 'Population', 'Confirmed.Cases', 'Deaths.Cases','Death.Ratio.Population', 'Confirmed.Ratio.Population', 'Death.Ratio.Confirmed') 


#COMPUTATION of the CENTERING MATRIX 
mcov <- scale(dataset_intermediaire_covid_correl)

na.omit(mcov)

#SAVING MCOV as a DATA FRAME
covariance_matrix <- as.data.frame(mcov)


#CORRELATION TEST with HANDLING of MISSING VALUES
mcor <- cor(covariance_matrix, method = "pearson", use = "complete.obs")

#SAVING MCOR as a DATA FRAME
correlation_matrix <- as.data.frame(mcor)

#DISPLAYING of CORRELATION GRAPHIC
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(mcor, method="color", col=col(200), type="upper", order="hclust", number.cex = .9, addCoef.col = "black", tl.col="black", tl.srt=45, insig = "blank", diag=TRUE )

```
By performing this correlation test on the dataset regrouping figures about covid-19, we see that the correlation between deaths and confirmed cases related to covid-19 is strong. This is no surprise as every critical or dead patient needs to be tested as the World health Organisation recommended. Furthermore, there is a strong correlation between the number of deaths per inhabitant and the number of confirmed cases per inhabitant.  
Others relations can be more surprising as the population and confirmed cases, or deaths cases, that are not related at all. This don't come as a matter of facts as we can picture that the more your population is big as a country, the more cases you should have.


```{r, error=FALSE, warning=FALSE, message=FALSE, fig.align='center', echo=FALSE}

#COMPUTATION of the P-VALUE COEEFICIENT
library(Hmisc)
p_value <- rcorr(as.matrix(correlation_matrix))

p_value_matrix <- as.data.frame(p_value$P)


#DISPLAYING of SIGNIFICANT P-VALUE CORRELATION GRAPHIC
library(corrplot)

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(p_value$r, method="color", col=col(200), type="upper", order="hclust", number.cex = .9, addCoef.col = "black", tl.col="black", tl.srt=45, p.mat = p_value$P, sig.level = 0.05, insig = "blank", diag=TRUE )


```
After performing a correlation test with p-value to determine whether the correlations obtained are significant or not, the correlations that still exist appear different. Indeed, only the correlation between the number of confirmed cases and the number of deaths appears to be significant.
A surprising negative correlation appears between the size of the country's population and its number of deaths relative to the population. Indeed, this correlation did not appear on the simple correlation test.


We perfom same test on our final dataset regrouping, for 147 countries, information about their revenues and governance style such as : Press Liberty index, Democracy index, Per Capita Income index, Corruption index, Rule of Law index, Government Effectiveness index, Voice and Accountability index and Service Capacity and Acces index.  We decided to run a correlation test to find pattern that could be interesting and to complete this test by a p-value test to confirm if correlations found are significant or not. To run this final test, the p-value chosen is 0.05.
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}

#LOADIND and SAVING of DATASET FINAL
dataset_intermediaire_clustering_correl <- select(dataset_final_clustering, 'RNB.Inhab.Year', 'Press.Liberty.Index', 'Democracy.Index','Voice Accountability', 'Corruption', 'Rule of Law', 'Government Effectiveness', 'Service Capacity and Access') 

#COMPUTATION of the CENTERING MATRIX 
mcov2 <- scale(dataset_intermediaire_clustering_correl)

na.omit(mcov2)

#SAVING MCOV as a DATA FRAME
covariance_matrix2 <- as.data.frame(mcov2)


#CORRELATION TEST with HANDLING of MISSING VALUES
mcor2 <- cor(covariance_matrix2, method = "pearson", use = "complete.obs")

#SAVING MCOR as a DATA FRAME
correlation_matrix2 <- as.data.frame(mcor2)

#DISPLAYING of CORRELATION GRAPHIC
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(mcor2, method="color", col=col(200), type="full", order="hclust", number.cex = .9, addCoef.col = "black", tl.col="black", tl.srt=45, insig = "blank", diag=TRUE )

```
This first correlation matrix shows us correlations between variables. 
Every intersection between a line and a columns represent the correlation between those two variables. The more the blue is intense, the more the correlation is strong. Numbers in colored squares represent the correlation. If, and only if, this number is above 0.5 then the correlation can be interpreted as strong. 
Even if strong correlations can be found, this first matrix can't tell us if those correlations are statistically confirmed, in other word that those correlations still exist after performing a p-value test on it.
We perform a p-value test to confirm or not correlations found. 
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}

#COMPUTATION of the P-VALUE COEEFICIENT
library(Hmisc)
p2_value <- rcorr(as.matrix(correlation_matrix2))

p_value_matrix2 <- as.data.frame(p2_value$P)

#DISPLAYING of SIGNIFICANT CORRELATION GRAPHIC
library(corrplot)

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(p2_value$r, method="color", col=col(200), type="full", order="hclust", number.cex = .9, addCoef.col = "black", tl.col="black", tl.srt=45, p.mat = p2_value$P, sig.level = 0.05, insig = "blank", diag=TRUE )
```
By doing this test, we clearly see that a lot of correlations precedently found, does not existe anymore. Every square still colored shows significant correlations. The blue ones a positive correlation, and red ones a negative one. 
By reading the matrix, we see that some indicators best decribe others, like the Rule of Law index which is strongly, and significantly, correlated to the RNB per Inhabitant per year, the Government effectiveness, the Corruption index. Therefore, if we only take it to perfom test, it will well represents the other ones.

## Country segmentation by k-mean algorithm 
After calculation of this correlation matrix under the p-value test, we decided to take only some of indicators to perfom a kmeans algorithm on a dataset of 147 countries. 
Our goal is to create groups of country based on the evaluation of their : Service Capacity and Access index, Rule of law index and Voice Accountability index. 
Before performing the kmeans algorithm, it is needed to by determine the optimal number of clusters. in order to avoid too vague clustering, it will be important not to fragment the dataset into more than 3 groups.  By doing so, the subgroups should contain more than the 30 individuals needed to perform statistically reliable tests. Having 148 countries, the ideal groups would contain in the 45 to 50 countries. 

The optimal number of clusters is determined prior to the execution of the kmeans agorithm. In order to determine this optimal number, the silhouette clustering test is performed. 
For each observation, the silhouette coefficient corresponds to the difference between the average distance with observations from the same group (cohesion) and the average distance with observations from other neighbouring groups (separation). If this difference is negative, the observation is on average closer to the neighbouring group than to its own: it is therefore misclassified. Conversely, if this difference is positive, the point is on average closer to its group than to the neighbouring group: it is therefore well ranked.
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
#TEST SUR LES KMEANS

library(factoextra)
library(purrr)
library(cluster)

#LOADING of the DATASET FINAL2 into DATASET KMEANS1
dataset_kmeans_clustering_temps <- dataset_final_clustering

#Making the FIRST COLUMNS as ROWNAMES
dataset_kmeans_clustering <- dataset_kmeans_clustering_temps[,-1]
rownames(dataset_kmeans_clustering) <- dataset_kmeans_clustering_temps[,1]


#DELETING UNWANTED COLUMNS
dataset_kmeans_clustering <- select(dataset_kmeans_clustering, 'Voice Accountability', 'Rule of Law', 'Service Capacity and Access') 


#STANDARDIZATON of the DATASET KMEANS
scale(dataset_kmeans_clustering)


#LOOKING FOR the best number of CLUSTERS by SILHOUETTE method
set.seed(40)

fviz_nbclust(dataset_kmeans_clustering, k.max = 5, kmeans, method = "silhouette")

```

This silhouette clustering algorithm shows that 2 cluster is the optimal number. However, in order to avoid a too imprecise partitioning, the dataset will be subdivided into 3 groups which corresponds to the second optimal partitioning.

3 groups of countries will therefore be determined by the K-mean algorithm, but it is necessary to ensure the quality of the resulting clusters,to do a Gap Statistic test is performed. The Gap Statistic is a method developed by R. Tibshirani, G. Walther, and T. Hastie from the Standford University in 2001. they describe their method in the following way : "The technique uses the output of any clustering algorithm, comparing the change in within-cluster dispersion with that expected under an appropriate reference null distribution". This means that the more the  gap statistic number for each k is high, the better this number of clusters (k) represent a good clustering.
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
#CALCULATING the QUALITY of the CLUSTERING depending on NUMBERS of CLUSTERS
gap_stat <- clusGap(dataset_kmeans_clustering, FUN = kmeans, nstart = 25,
                    K.max = 5, B = 50)

#PRINT the RESULT
print(gap_stat, method = "firstmax")

fviz_gap_stat(gap_stat)

```
If 2 clusters still represents the optimal number of clusters, as the Silhouette method already indicated, 3 being the second best option, it is possible to choose 3 as the optimal number of clusters. This method is particularly sensitive to cluster overlapping which can explain why 3 is not the optimal number of clusters. Confirmation will be made by seeing groups of countries during the performation of the k-means algorithm.
keeping in mind that 30 countries for each clusters is a minimum to perform statistics, 5 in the maximum number of clusters tested. Indeed, if 5 clusters are created they will contain less than 30 countries in each one and thus, statistical tests cannot be performed.


Once all the parameters of the k-mean algorithm have been determined, it should be applied to the dataset containing the variables selected for each country that are : : Voice Accoutability index, Rule of Law index and Service Capacity and Access index.
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
#APPLYING the KMEANS ALGORITHM
set.seed(2450)
clusters <- kmeans(dataset_kmeans_clustering, 3, nstart = 25)

fviz_cluster(clusters, data = dataset_kmeans_clustering)

#SAVING the COUNTRY'S CLUSTER NUMBER into DATASET FINAL2
dataset_kmeans_clustering$Cluster <- clusters$cluster


```
3 groups of 66, 32 and 50 countries sharing common characteristics according to the selected variables are obtained. As previously suspected, overlapping cluster can be observed which means that this clustering cannot be the best one. With that said, this overlapping is due to only 3 countries which does not represent a threat for the overhall clustering.  

Saving dataset final in a excel file
```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}

#SAVING DATASET FINAL in a EXCEL FILE
write_xlsx(x = dataset_kmeans_clustering, path = "Datasets/dataset_kmeans_clustering.xlsx", col_names = TRUE)

```


## Covid-19 impact statistics by cluster 

Once 3 clusters of countries have been obtained, analyses will be carried out to determine the impact of covid-19 on the countries belonging to the same cluster. 
Here, these analyses will focus on cluster 1 which includes the countries of the European Union, but also the largest countries in the world in terms of geopolitics. 

```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}

#RETRIEVING DATASET KMEANS CLUSTERING to add COUNTRY COLUMN
dataset_cluster_1_temp <- dataset_kmeans_clustering
dataset_cluster_1_temp$Country <- dataset_final_clustering$Country

#FILTERING only COUNTRIES in the CLUSTER 1
dataset_cluster_1 <- filter(dataset_cluster_1_temp, dataset_cluster_1_temp$Cluster == "1")

#MOVING COLUMNS in order to have COUNTRY'S NAME as FIRST COLUMN
dataset_cluster_1 <- dataset_cluster_1[, c(5, 1, 2, 3, 4)]
dataset_cluster_1 <- as.data.frame(dataset_cluster_1)

#SELECTION of COVID NUMBERS for countries in the CLUSTER 1 ONLY
dataset_covid_cluster_1 <- filter(dataset_final_covid, dataset_final_covid$Country %in% dataset_cluster_1$Country)

#dataset_covid_cluster_1$ISO <- dataset_cluster_1$

#COMPUTATION of MEANS for EACH COLUMNS
means_covid_cluster_1 <- colMeans(dataset_covid_cluster_1[4:9])
means_covid_cluster_1 <- as.data.frame(means_covid_cluster_1)


#DELETING ISO2 COLUMN
dataset_covid_cluster_1$ISO2 <- NULL

#RETRIEVING COVID INFORMATIONS by COUNTRY
dataset_covid_10_countries <- subset(dataset_covid_cluster_1, dataset_covid_cluster_1$ISO %in% c("LBY","BRA","KOR","SWE","FRA","DEU","CHN","USA","GBR","PRT"))

```




```{r,echo=FALSE, error=FALSE, warning=FALSE, message=FALSE, fig.align='center'}


library(ggplot2)
library(ggthemes)

ggplot(x = Portugal_covid$Death.Ratio.Population, y = Portugal_covid$Population)

```


